## TODO
1. EMA（占用显存太大了）
2. --tf_log 会报错
3. 根据fid下降的特点，仿照torch实现阶梯下降的学习率策略
4. 先测试lr_scheduler的使用方法（last_epoch的使用）
5. labelmix